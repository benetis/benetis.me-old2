<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>mysql on Typical personal blog</title>
    <link>https://benetis.me/old/tags/mysql/</link>
    <description>Recent content in mysql on Typical personal blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; All rights reserved</copyright>
    <lastBuildDate>Sun, 06 Aug 2017 18:54:24 +0200</lastBuildDate><atom:link href="https://benetis.me/old/tags/mysql/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Real estate ads scraping with Scala and Akka - Proof of concept</title>
      <link>https://benetis.me/old/posts/real-estate-prices/</link>
      <pubDate>Sun, 06 Aug 2017 18:54:24 +0200</pubDate>
      
      <guid>https://benetis.me/old/posts/real-estate-prices/</guid>
      <description>Introduction Disclaimer: Not an expert in scala world - any feedback is appreciated.
A question came to mind - can I crawl through a real estate website, gather some data and infer something from that data. This is also becoming relevant and interesting to me.
What experience I want to get doing this side project:
 Data scraping (common problems, &amp;hellip;) Concurrency while analyzing, gathering data (Akka Aktors) Data analysis, statistical inference (Knowing what to query and what results mean) Data visualization (how to display data in a meaningful way) DevOps experience (long running app: deploy, updates, backups, &amp;hellip;)  Planning phase How I imagine this little spider would work:</description>
    </item>
    
  </channel>
</rss>
